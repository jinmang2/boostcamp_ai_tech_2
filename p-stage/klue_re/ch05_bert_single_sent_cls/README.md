# 5ê°• BERT ê¸°ë°˜ ë‹¨ì¼ ë¬¸ì¥ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ

3ê°•ì—ì„œ ë°°ìš´ BERTë¥¼ ê°€ì§€ê³  ìì—°ì–´ ì²˜ë¦¬ Taskë¥¼ í•´ê²°í•´ ë´…ë‹ˆë‹¤. ğŸ§

ë‹¨ì¼ ë¬¸ì¥ ë¶„ë¥˜ ëª¨ë¸ì€ ì£¼ì–´ì§„ ë¬¸ì¥ì— ëŒ€í•˜ì—¬ íŠ¹ì • ë¼ë²¨ì„ ì˜ˆì¸¡í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

í™œìš© ë¶„ì•¼ë¡œëŠ” ë¦¬ë·°ì˜ ê¸ì •/ë¶€ì • ë“±ì˜ ê°ì„± ë¶„ì„, ë‰´ìŠ¤ì˜ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜, ë¹„ì†ì–´ íŒë‹¨ ëª¨ë¸ ë“±ì´ ìˆìŠµë‹ˆë‹¤.

<details open="open">
  <summary>Table of Contents</summary>
  <ol>
    <li>
      <a href="#1-klue-ë°ì´í„°ì…‹-ì†Œê°œ">KLUE ë°ì´í„°ì…‹ ì†Œê°œ</a>
      <ul>
        <li><a href="#11-klue-ë°ì´í„°ì…‹">KLUE ë°ì´í„°ì…‹</a></li>
      </ul>
    </li>
    <li>
      <a href="#2-ë‹¨ì¼-ë¬¸ì¥-ë¶„ë¥˜-task-ì†Œê°œ">ë‹¨ì¼ ë¬¸ì¥ ë¶„ë¥˜ task ì†Œê°œ</a>
      <ul>
        <li><a href="#21-ë¬¸ì¥-ë¶„ë¥˜-task">ë¬¸ì¥ ë¶„ë¥˜ task</a></li>
        <li><a href="#22-ë¬¸ì¥-ë¶„ë¥˜ë¥¼-ìœ„í•œ-ë°ì´í„°">ë¬¸ì¥ ë¶„ë¥˜ë¥¼ ìœ„í•œ ë°ì´í„°</a></li>
      </ul>
    </li>
    <li><a href="#3-ë‹¨ì¼-ë¬¸ì¥-ë¶„ë¥˜-ëª¨ë¸-í•™ìŠµ">ë‹¨ì¼ ë¬¸ì¥ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ</a></li>
  </ol>
</details>

## 1. KLUE ë°ì´í„°ì…‹ ì†Œê°œ
ê³¼ì œì—ì„œ ì‚¬ìš©ë  KLUE ë°ì´í„°ì…‹ ì†Œê°œ

### 1.1 KLUE ë°ì´í„°ì…‹
- Korean Language Understanding Evaluation
    - ë¬¸ì¥ ë¶„ë¥˜ (5ê°•)
    - ê´€ê³„ ì¶”ì¶œ (5ê°•)
    - ë¬¸ì¥ ìœ ì‚¬ë„ (e.g, [CLS])
    - ìì—°ì–´ ì¶”ë¡  (6ê°•)
    - ê°œì²´ëª… ì¸ì‹ (7ê°•)
    - í’ˆì‚¬ íƒœê¹… (7ê°•)
    - ì§ˆì˜ ì‘ë‹µ (7ê°•)
    - ëª©ì í˜• ëŒ€í™” (ê¹€ì„±ë™ë‹˜ DSTê°•ì˜)
    - ì˜ì¡´ êµ¬ë¬¸ ë¶„ì„ (ã…ã…)

#### ì˜ì¡´ êµ¬ë¬¸ ë¶„ì„?

![img](../../../assets/img/p-stage/klue_05_01.PNG)

1. íŠ¹ì§•
    - ì§€ë°°ì†Œ: ì˜ë¯¸ì˜ ì¤‘ì‹¬ì´ ë˜ëŠ” ìš”ì†Œ
    - ì˜ì¡´ì†Œ: ì§€ë°°ì†Œê°€ ê°–ëŠ” ì˜ë¯¸ë¥¼ ë³´ì™„í•´ì£¼ëŠ” ìš”ì†Œ (ìˆ˜ì‹)
    - ì–´ìˆœê³¼ ìƒëµì´ ììœ ë¡œìš´ í•œêµ­ì–´ì™€ ê°™ì€ ì–¸ì–´ì—ì„œ ì£¼ë¡œ ì—°êµ¬

2. ë¶„ë¥˜ ê·œì¹™
    - ì§€ë°°ì†ŒëŠ” í›„ìœ„ì–¸ì–´. ì¦‰, ì§€ë°°ì†ŒëŠ” í•­ìƒ ì˜ì¡´ì†Œë³´ë‹¤ ë’¤ì— ìœ„ì¹˜
    - ê° ì˜ì¡´ì†Œì˜ ì§€ë°°ì†ŒëŠ” í•˜ë‚˜
    - êµì°¨ ì˜ì¡´ êµ¬ì¡°ëŠ” ì—†ìŒ
3. ë¶„ë¥˜ ë°©ë²•
    - Sequence Labeling ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬ ë‹¨ê³„ë¥¼ ë‚˜ëˆ”
    - ì• ì–´ì ˆì— ì˜ì¡´ì†Œê°€ ì—†ê³  ë‹¤ìŒ ì–´ì ˆì´ ì§€ë°°ì†Œì¸ ì–´ì ˆì„ ì‚­ì œí•˜ë©° ì˜ì¡´ ê´€ê³„ë¥¼ ë§Œë“¦

![img](../../../assets/img/p-stage/klue_05_02.PNG)

- ì´ë¥¼ í†µí•´ ë³µì¡í•œ ìì—°ì–´ í˜•íƒœë¥¼ ê·¸ë˜í”„ë¡œ êµ¬ì¡°í™”í•´ì„œ í‘œí˜„í•  ìˆ˜ ìˆë‹¤!

<br/>
<div align="right">
    <b><a href="#5ê°•-bert-ê¸°ë°˜-ë‹¨ì¼-ë¬¸ì¥-ë¶„ë¥˜-ëª¨ë¸-í•™ìŠµ">â†¥ back to top</a></b>
</div>
<br/>

## 2. ë‹¨ì¼ ë¬¸ì¥ ë¶„ë¥˜ task ì†Œê°œ

### 2.1 ë¬¸ì¥ ë¶„ë¥˜ task

#### ê°ì •ë¶„ì„(Sentiment Analysis)
- ë¬¸ì¥ì˜ ê¸/ë¶€ì • ë˜ëŠ” ì¤‘ë¦½ ë“± ì„±í–¥ì„ ë¶„ë¥˜í•˜ëŠ” í”„ë¡œì„¸ìŠ¤
- ê¸°ì—…ì—ì„œ ëª¨ë‹ˆí„°ë§, ê³ ê°ì§€ì› ë˜ëŠ” ëŒ“ê¸€ í•„í„°ë§ ìë™í™”í•˜ëŠ” ì‘ì—…ì— ì£¼ë¡œ ì‚¬ìš©
- í™œìš© ë°©ì•ˆ
    - í˜ì˜¤ ë°œì–¸ ë¶„ë¥˜: ëŒ“ê¸€, ê²Œì„ ëŒ€í™” ë“± í˜ì˜¤ ë°œì–¸ ë¶„ë¥˜í•˜ì—¬ ì¡°ì¹˜ë¥¼ ì·¨í•˜ëŠ” ìš©ë„ë¡œ í™œìš©
    - ê¸°ì—… ëª¨ë‹ˆí„°ë§: ì†Œì…œ, ë¦¬ë·° ë“± ë°ì´í„°ì— ëŒ€í•´ ê¸°ì—… ì´ë¯¸ì§€, ë¸Œëœë“œ ì„ í˜¸ë„, ì œí’ˆí‰ê°€ ë“± ê¸/ë¶€ì • ìš”ì¸ ë¶„ì„

#### ì£¼ì œ ë¼ë²¨ë§(Topic Labeling)
- ë¬¸ì¥ì˜ ë‚´ìš©ì„ ì´í•´, ì ì ˆí•œ ë²”ì£¼ë¡œ ë¶„ë¥˜
- í™œìš© ë°©ì•ˆ
    - ëŒ€ìš©ëŸ‰ ë¬¸ì„œ ë¶„ë¥˜
    - VoC(Voice of Customer): ê³ ê°ì˜ í”¼ë“œë°±ì„ ì œí’ˆ ê°€ê²©, ê°œì„ ì , ë””ìì¸ ë“± ì ì ˆí•œ ì£¼ì œë¡œ ë¶„ë¥˜í•˜ì—¬ ë°ì´í„°ë¥¼ êµ¬ì¡°í™”

#### ì–¸ì–´ ê°ì§€(Language Detection)
- ë¬¸ì¥ì´ ì–´ë–¤ ë‚˜ë¼ ì–¸ì–´ì¸ì§€ë¥¼ ë¶„ë¥˜
- ë²ˆì—­ê¸°ì—ì„œ ì •í™•í•œ ë²ˆì—­ì„ ìœ„í•´ ì–´ë–¤ ì–¸ì–´ì¸ì§€ íƒ€ì¼“íŒ…
- í™œìš© ë°©ì•ˆ
    - ë²ˆì—­ê¸°: ë³€ì—­í•  ë¬¸ì¥ì— ëŒ€í•´ ì ì ˆí•œ ì–¸ì–´ë¥¼ ê°ì§€
    - í…Œì´í„° í•„í„°ë§: íƒ€ì¼“ ì–¸ì–´ ì´ì™¸ ë°ì´í„°ëŠ” í•„í„°ë§

#### ì˜ë„ ë¶„ë¥˜(Intent Classification)
- ë¬¸ì¥ì´ ê°€ì§„ ì˜ë„ë¥¼ ë¶„ë¥˜í•˜ëŠ” í”„ë¡œì„¸ìŠ¤
- í™œìš© ë°©ì•ˆ
    - ì±—ë´‡: ë¬¸ì¥ì˜ ì˜ë„ì¸ ì§ˆë¬¸, ëª…ë ¹, ê±°ì ˆ ë“±ì„ ë¶„ì„, ì ì ˆí•œ ë‹µë³€ì„ ì£¼ê¸° ìœ„í•´ í™œìš©

<br/>
<div align="right">
    <b><a href="#5ê°•-bert-ê¸°ë°˜-ë‹¨ì¼-ë¬¸ì¥-ë¶„ë¥˜-ëª¨ë¸-í•™ìŠµ">â†¥ back to top</a></b>
</div>
<br/>

### 2.2 ë¬¸ì¥ ë¶„ë¥˜ë¥¼ ìœ„í•œ ë°ì´í„°

#### kor_hate
- í˜ì˜¤ í‘œí˜„ì— ëŒ€í•œ ë°ì´í„°
- íŠ¹ì • ê°œì¸ ë˜ëŠ” ì§‘ë‹¨ì— ëŒ€í•œ ê³µê²©ì  ë¬¸ì¥
- ë¬´ë¡€, ê³µê²©ì ì´ê±°ë‚˜ ë¹„ê¼¬ëŠ” ë¬¸ì¥
- ë¶€ì •ì ì´ì§€ ì•Šì€ ë¬¸ì¥

![img](../../../assets/img/p-stage/klue_05_03.PNG)

#### kor_sarcasm
- ë¹„ê¼¬ì§€ ì•Šì€ í‘œí˜„ì˜ ë¬¸ì¥
- ë¹„ê¼¬ëŠ” í‘œí˜„ì˜ ë¬¸ì¥

![img](../../../assets/img/p-stage/klue_05_04.PNG)

#### kor_sae
- ì˜ˆ/ì•„ë‹ˆì˜¤ë¡œ ë‹µë³€ ê°€ëŠ¥í•œ ì§ˆë¬¸
- ëŒ€ì•ˆ ì„ íƒì„ ë¬¼ì–´ë´„
- (who, what, where, when, why, how) ì§ˆë¬¸
- ê¸ˆì§€, ìš”êµ¬, ê°•í•œ ìš”êµ¬

![img](../../../assets/img/p-stage/klue_05_05.PNG)

#### Kor_3i4k
- ë‹¨ì–´ or ë¬¸ì¥ ì¡°ê°
- í‰ì„œë¬¸, ì§ˆë¬¸, ëª…ë ¹ë¬¸, ìˆ˜ì‚¬ì  ì§ˆë¬¸, ìˆ˜ì‚¬ì  ëª…ë ¹ë¬¸, ì–µì–‘ì— ì˜ì¡´í•˜ëŠ” ì˜ë„

![img](../../../assets/img/p-stage/klue_05_06.PNG)

<br/>
<div align="right">
    <b><a href="#5ê°•-bert-ê¸°ë°˜-ë‹¨ì¼-ë¬¸ì¥-ë¶„ë¥˜-ëª¨ë¸-í•™ìŠµ">â†¥ back to top</a></b>
</div>
<br/>

## 3. ë‹¨ì¼ ë¬¸ì¥ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ

### ëª¨ë¸ êµ¬ì¡°ë„
![img](../../../assets/img/p-stage/klue_05_07.PNG)

### í•™ìŠµ ê³¼ì •
![img](../../../assets/img/p-stage/klue_05_08.PNG)

<br/>
<div align="right">
    <b><a href="#5ê°•-bert-ê¸°ë°˜-ë‹¨ì¼-ë¬¸ì¥-ë¶„ë¥˜-ëª¨ë¸-í•™ìŠµ">â†¥ back to top</a></b>
</div>
<br/>

### ì½”ë“œ ì‹¤ìŠµ
- ëª¨ë¥´ëŠ” ì½”ë“œ í˜¹ì€ ë„ì›€ì´ ë ë§Œí•œ ì½”ë“œë§Œ ê¸°ì…

```python
# ì¤‘ë³µ ë°ì´í„° ì œê±°
train_data.drop_duplicates(subset=['document'], inplace= True)
test_data.drop_duplicates(subset=['document'], inplace= True)

# null ë°ì´í„° ì œê±°
train_data['document'].replace('', np.nan, inplace=True)
test_data['document'].replace('', np.nan, inplace=True)
train_data = train_data.dropna(how = 'any')
test_data = test_data.dropna(how = 'any')
```

- ì˜ˆì¸¡í•¨ìˆ˜ë¥¼ huggingface Trainerì˜ predictë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³  ì§ì ‘ torchë¡œ êµ¬ì¶•í•˜ì‹¬

```python
# predictí•¨ìˆ˜
def sentences_predict(sent):
    model.eval()
    tokenized_sent = tokenizer(
            sent,
            return_tensors="pt",
            truncation=True,
            add_special_tokens=True,
            max_length=128
    )
    tokenized_sent.to(device)

    with torch.no_grad():# ê·¸ë¼ë””ì—”íŠ¸ ê³„ì‚° ë¹„í™œì„±í™”
        outputs = model(
            input_ids=tokenized_sent['input_ids'],
            attention_mask=tokenized_sent['attention_mask'],
            token_type_ids=tokenized_sent['token_type_ids']
            )

    logits = outputs[0]
    logits = logits.detach().cpu().numpy()
    result = np.argmax(logits)
    return result
```




## Reference
- [BERT Text Classification Using Pytorch](https://towardsdatascience.com/bert-text-classification-using-pytorch-723dfb8b6b5b)
- [Sentiment Analysis with BERT](https://curiousily.com/posts/sentiment-analysis-with-bert-and-hugging-face-using-pytorch-and-python/)
- [ë„¤ì´ë²„ ì˜í™”ë¦¬ë·° ê°ì •ë¶„ì„](https://colab.research.google.com/drive/1tIf0Ugdqg4qT7gcxia3tL7und64Rv1dP)
- [Sequence Classification using Pytorch Lightning with BERT](https://knswamy.medium.com/sequence-classification-using-pytorch-lightning-with-bert-on-imbd-data-5e9f48baa638)
- [BERT Fine-Tuning Tutorial with PyTorch](https://mccormickml.com/2019/07/22/BERT-fine-tuning/)



<br/>
<div align="right">
    <b><a href="#5ê°•-bert-ê¸°ë°˜-ë‹¨ì¼-ë¬¸ì¥-ë¶„ë¥˜-ëª¨ë¸-í•™ìŠµ">â†¥ back to top</a></b>
</div>
<br/>
