# 6ê°• BERT ê¸°ë°˜ ë‘ ë¬¸ì¥ ê´€ê³„ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ

3ê°•ì—ì„œ ë°°ìš´ BERTë¥¼ ê°€ì§€ê³  ìì—°ì–´ ì²˜ë¦¬ Taskë¥¼ í•´ê²°í•´ ë´…ë‹ˆë‹¤. ğŸ¥´

ë‘ ë¬¸ì¥ ê´€ë¡€ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµì€ ì£¼ì–´ì§„ ë‘ ë¬¸ì¥ì— ëŒ€í•˜ì—¬ ë‘ ë¬¸ì¥ì— ëŒ€í•œ ë¼ë²¨ì„ ì˜ˆì¸¡í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

5ê°•ì˜ ë‹¨ì¼ ë¬¸ì¥ ë¶„ë¥˜ ëª¨ë¸ê³¼ì˜ ê°€ì¥ í° ì°¨ì´ì ì€ Input ë¬¸ì¥ì˜ ê°œìˆ˜ì…ë‹ˆë‹¤.

ë‘ ë¬¸ì¥ ê´€ê³„ ë¶„ë¥˜ ëª¨ë¸ì—ì„œëŠ” 2ê°œì˜ ë¬¸ì¥ì„ ë°›ì•„ ê·¸ ë¬¸ì¥ë“¤ì˜ ê´€ê³„ì— í•´ë‹¹í•˜ëŠ” ë¼ë²¨ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.ğŸ˜š

[back to super](https://github.com/jinmang2/boostcamp_ai_tech_2/tree/main/p-stage/klue_re)

<details open="open">
  <summary>Table of Contents</summary>
  <ol>
    <li>
      <a href="#ë‘-ë¬¸ì¥-ê´€ê³„-ë¶„ë¥˜-task-ì†Œê°œ">ë‘ ë¬¸ì¥ ê´€ê³„ ë¶„ë¥˜ task ì†Œê°œ</a>
      <ul>
        <li><a href="#task-ì†Œê°œ">task ì†Œê°œ</a></li>
        <li><a href="#ë‘-ë¬¸ì¥-ê´€ê³„-ë¶„ë¥˜ë¥¼-ìœ„í•œ-ë°ì´í„°">ë‘ ë¬¸ì¥ ê´€ê³„ ë¶„ë¥˜ë¥¼ ìœ„í•œ ë°ì´í„°</a></li>
      </ul>
    </li>
    <li>
      <a href="#ëª¨ë¸-í•™ìŠµ-ì‹¤ìŠµ">ëª¨ë¸ í•™ìŠµ ì‹¤ìŠµ</a>
      <ul>
        <li><a href="#21-information-retrieval-question-and-answering-irqa">Information Retrieval Question and Answering (IRQA)</a></li>
        <li><a href="#ë‘-ë¬¸ì¥-ê´€ê³„-ë¶„ë¥˜ë¥¼-ìœ„í•œ-í•™ìŠµ-ë°ì´í„°-êµ¬ì¶•">ë‘ ë¬¸ì¥ ê´€ê³„ ë¶„ë¥˜ë¥¼ ìœ„í•œ í•™ìŠµ ë°ì´í„° êµ¬ì¶•</a></li>
        <li><a href="#ë‘-ë¬¸ì¥-ê´€ê³„-ë¶„ë¥˜-í•™ìŠµ">ë‘ ë¬¸ì¥ ê´€ê³„ ë¶„ë¥˜ í•™ìŠµ</a></li>
        <li><a href="#bert-irqa-ê¸°ë°˜ì˜-ì±—ë´‡-ì‹¤ìŠµ">BERT IRQA ê¸°ë°˜ì˜ ì±—ë´‡ ì‹¤ìŠµ</a></li>
      </ul>
    </li>
  </ol>
</details>

## 1. ë‘ ë¬¸ì¥ ê´€ê³„ ë¶„ë¥˜ task ì†Œê°œ

### 1.1 task ì†Œê°œ
- ì£¼ì–´ì§„ 2ê°œì˜ ë¬¸ì¥ì— ëŒ€í•´ ë‘ ë¬¸ì¥ì˜ ìì—°ì–´ ì¶”ë¡ ê³¼ ì˜ë¯¸ë¡ ì ì¸ ìœ ì‚¬ì„±ì„ ì¸¡ì •í•˜ëŠ” task

![img](../../../assets/img/p-stage/klue_06_01.PNG)

<br/>
<div align="right">
    <b><a href="#6ê°•-bert-ê¸°ë°˜-ë‘-ë¬¸ì¥-ê´€ê³„-ë¶„ë¥˜-ëª¨ë¸-í•™ìŠµ">â†¥ back to top</a></b>
</div>
<br/>

### ë‘ ë¬¸ì¥ ê´€ê³„ ë¶„ë¥˜ë¥¼ ìœ„í•œ ë°ì´í„°
- Natural Language Processing (NLI)
    - premiseì™€ hypothesisê°€ ì£¼ì–´ì§
    - entailment(í•¨ì˜), contradiction(ëª¨ìˆœ), neutral(ì¤‘ë¦½)ìœ¼ë¡œ ë¶„ë¥˜

![img](../../../assets/img/p-stage/klue_06_02.PNG)

- Semantic text pair
    - ë‘ ë¬¸ì¥ì˜ ì˜ë¯¸ê°€ ì„œë¡œ ê°™ì€ ë¬¸ì¥ì¸ì§€ ê²€ì¦

![img](../../../assets/img/p-stage/klue_06_03.PNG)

<br/>
<div align="right">
    <b><a href="#6ê°•-bert-ê¸°ë°˜-ë‘-ë¬¸ì¥-ê´€ê³„-ë¶„ë¥˜-ëª¨ë¸-í•™ìŠµ">â†¥ back to top</a></b>
</div>
<br/>

## 2. ëª¨ë¸ í•™ìŠµ ì‹¤ìŠµ

BERTë¡œ IRQA ì±—ë´‡ì„ ë§Œë“¤ì–´ë´…ì‹œë‹¤!

### 2.1 Information Retrieval Question and Answering (IRQA)

![img](../../../assets/img/p-stage/klue_06_04.PNG)

<br/>
<div align="right">
    <b><a href="#6ê°•-bert-ê¸°ë°˜-ë‘-ë¬¸ì¥-ê´€ê³„-ë¶„ë¥˜-ëª¨ë¸-í•™ìŠµ">â†¥ back to top</a></b>
</div>
<br/>

### ë‘ ë¬¸ì¥ ê´€ê³„ ë¶„ë¥˜ë¥¼ ìœ„í•œ í•™ìŠµ ë°ì´í„° êµ¬ì¶•

- ì¡°ì›ìµë‹˜ ì œì‘
- í•œ ë¬¸ì¥ì— ëŒ€í•´ 10ê°œì˜ paraphrasingëœ pairê°€ ì¡´ì¬

```python
$ git clone https://github.com/warnikchow/paraKQC.git
```

- ê´€ê³„ ë¶„ë¥˜ë¥¼ ìœ„í•´ 1ê°œì— 9ê°œ ì—°ê´€ sentenceë¡œ ë¬¶ìŒ
- ì ‘ê·¼ë°©ë²•: ë‚˜ë¨¸ì§€ ë¬¸ì¥ì—ì„œ randomí•˜ê²Œ ë½‘ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ë‚˜ë¨¸ì§€ ë¬¸ì¥ì„ ë¯¸ë¦¬ sentence embeddingìœ¼ë¡œ ê³„ì‚°í•´ë‘ê³ 
- ì´ ì¤‘ ê°€ì¥ ìœ ì‚¬ë„ê°€ ë†’ê²Œ ë‚˜ì˜¤ëŠ” ë¬¸ì¥ì„ ì„ íƒ
- ì´ëŸ¬ë©´ ëª¨ë¸ ì…ì¥ì—ì„  ë¹„ìŠ·í•˜ë‚˜ ì˜ë¯¸ë¡ ì ìœ¼ë¡  ë‹¤ë¥¸ sampleì´ ë½‘í˜

```python
# êµ‰ì¥íˆ ìœ ìš©í•œ í•¨ìˆ˜
def get_cls_token(sent_A):
    model.eval()
    tokenized_sent = tokenizer(
            sent_A,
            return_tensors="pt",
            truncation=True,
            add_special_tokens=True,
            max_length=32
    ).to('cuda:0')
    with torch.no_grad():# ê·¸ë¼ë””ì—”íŠ¸ ê³„ì‚° ë¹„í™œì„±í™”
        outputs = model(
            input_ids=tokenized_sent['input_ids'],
            attention_mask=tokenized_sent['attention_mask'],
            token_type_ids=tokenized_sent['token_type_ids']
            )
    logits = outputs.last_hidden_state[:,0,:].detach().cpu().numpy()
    return logits
```

- í‚¤ì›Œë“œëŠ” ë¹„ìŠ·í•˜ì§€ë§Œ ì˜ë¯¸ë¡ ì ìœ¼ë¡œ ìœ ì‚¬í•œ ê²ƒë“¤ì„ ê°€ì ¸ì˜¤ê²Œ ëœë‹¤.

```python
ë©”ì¼ì„ ë‹¤ ë¹„ìš¸ê¹Œ ì•„ë‹ˆë©´ ì•ˆì½ì€ ê²ƒë§Œ ì§€ìš¸ê¹Œ?
- ('ì•ˆë°© ë§ê³  ì§€ê¸ˆ ê±°ì‹¤ ì˜¨ë„ ì¢€ ë³¼ ìˆ˜ ìˆì„ê¹Œ?', array([[0.98267]], dtype=float32))
- ('ì•ˆ ì½ì€ ë©”ì¼í•¨ì´ë‘ ìŠ¤íŒ¸ ë©”ì¼í•¨ì´ë‘ ë¹„êµí–ˆì„ ë•Œ ì–´ë””ê°€ ë” ì°¨ìˆì§€?', array([[0.97837853]], dtype=float32))
- ('ê°€ìŠµê¸°ê°€ í•„ìš”í•œê²Œ ì•„ë‹ˆê³  ì œìŠµê¸° í•˜ë‚˜ ì‚¬ì•¼ë  ê²ƒ ê°™ì§€ ì•Šì•„?', array([[0.97624516]], dtype=float32))
- ('ì¼ì›”ì´ ë°”ì˜ì‹ ê°€ìš”, ì•„ë‹ˆë©´ ì´ì›”ì´ ë” ë°”ì˜ì‹ ê°€ìš”?', array([[0.97588336]], dtype=float32))
- ('ì•ˆë°©í•˜ê³  ê±°ì‹¤ ì¤‘ì— ë„ˆê°€ ë¡œë´‡ì²­ì†Œê¸°ë¥¼ í‹€ê³  ì‹¶ì€ ê³³ì€ ì–´ë”œê¹Œ?', array([[0.97562]], dtype=float32))
- ('ì•ˆë°© ë§ê³  ê±°ì‹¤ ì˜¨ë„ ë³´ë ¤ë©´ ì–´ë–»ê²Œ ë§í•´ì•¼í•˜ë‚˜?', array([[0.97547626]], dtype=float32))
- ('ì§€ê¸ˆ ë„¤ê°€ í•˜ê³  ì‹¶ì€ê²Œ ì™¸ì¶œëª¨ë“œì¼ê¹Œ ì•„ë‹˜ ë°©ë²”ëª¨ë“œì¼ê¹Œ?', array([[0.9754139]], dtype=float32))
- ('ë©”ì¼ì„ ìƒì‚¬ì—ê²Œ ì–´ë–»ê²Œ ë³´ë‚´ì•¼í•´?', array([[0.9753622]], dtype=float32))
- ('ì•ˆë°© ë§ê³  ê±°ì‹¤ ì§€ê¸ˆ ì˜¨ë„ ë³´ë ¤ë©´ ë­ë¼ê³  í•´ì•¼í•´?', array([[0.9751789]], dtype=float32))
- ('ëª©ìš•ë¬¼ì„ ê°œì¸ë³„ë¡œ ì„¸íŒ…í•˜ê³  ì‹¶ì€ë°ìš” ì–´ë–»ê²Œ í•˜ë©´ ì¢‹ì„ê¹Œìš”?', array([[0.97513217]], dtype=float32))

ì§€ë©”ì¼ ì“¸ë˜, ë„¤ì´ë²„ ë©”ì¼ ì“¸ë˜
- ('í•œë©”ì¼ ê³„ì •ì€ ê·¸ë§Œ ë§Œë“¤ê³  ë„¤ì´ë²„ ê³„ì •ìœ¼ë¡œ ë§Œë“¤ì–´', array([[0.9531825]], dtype=float32))
- ('ì°¸ì¡° ë©”ì¼ì£¼ì†ŒëŠ” ëª¨ìœ¼ì§€ ì•Šì•„ë„ ë¼. ë³´ë‚¸ ì‚¬ëŒ ì¤‘ì—ì„œ íŠ¹ìˆ˜ë¬¸ìê°€ ìˆëŠ” ë©”ì¼ì£¼ì†Œë§Œ ëª¨ì•„ì¤˜.', array([[0.9495812]], dtype=float32))
- ('ëª¨ë‹ˆí„°ë§ê³  ë¹”í”„ë¡œì í„°ë¡œ ì˜í™” ë„ì›Œì„œ ë³´ì', array([[0.9486408]], dtype=float32))
- ('ì•„ì›ƒë£© ì™¸ë¶€ ì—°ë™ ë©”ì¼ì´ ì„¸ê°œ ì´ìƒì´ ë˜ì§€ ì•Šë„ë¡ ì—°ë™ ê°œìˆ˜ë¥¼ í™•ì¸í•˜ê³ , ì„¸ê°œ ì´ìƒì¸ ê²½ìš° ë‘ê°œë¡œ ì¤„ì´ì‹œê¸° ë°”ëë‹ˆë‹¤.', array([[0.94794756]], dtype=float32))
- ('usbë¡œ íŒŒì¼ì„ ì „ë‹¬í•˜ì§€ ë§ê³  ë„¤ì´ë²„ ë©”ì¼ë¡œ ë³´ë‚´', array([[0.94788885]], dtype=float32))
- ('íŒŒì¼ ì „ì†¡ì€ ì§€ë©”ì¼ ë³´ë‹¨ ë„¤ì´ë²„ ë©”ì¼ì„ ì‚¬ìš©í•´', array([[0.9477933]], dtype=float32))
- ('ë©”ì¼ì„ ì§€ìš¸ ë•Œ ì²¨ë¶€íŒŒì¼ ìš©ëŸ‰ì´ ì‘ì€ ë©”ì¼ì€ ë‚¨ê²¨ë‘ê³ , í° ë©”ì¼ì€ ì „ë¶€ ì§€ìš°ëŠ”ê²Œ ì¢‹ì•„.', array([[0.9470954]], dtype=float32))
- ('ë‹¤ë¥¸ ì´ë©”ì¼ì„ ì‚¬ìš©í•´. ì§€ë©”ì¼ì€ ì•ˆë¼', array([[0.9469803]], dtype=float32))
- ('ë¦¬ëˆ…ìŠ¤ì—ì„œ ì œê³µí•˜ëŠ” ë©”ì¼ê´€ë¦¬ ê¸°ëŠ¥ê³¼ ìœˆë„ìš°ì—ì„œ ì œê³µí•˜ëŠ” ë©”ì¼ ê´€ë¦¬ ê¸°ëŠ¥ ì¤‘ ë­ê°€ ë” í¸í–ˆë‹ˆ?', array([[0.9469311]], dtype=float32))
- ('ì•„ì›ƒë£©ì€ ë¦¬ëˆ…ìŠ¤ê°€ ì•„ë‹Œ ìš´ì˜ì²´ì œì—ì„œ ì´ìš©í•˜ê¸¸ ë°”ë˜', array([[0.94628114]], dtype=float32))
```

<br/>
<div align="right">
    <b><a href="#6ê°•-bert-ê¸°ë°˜-ë‘-ë¬¸ì¥-ê´€ê³„-ë¶„ë¥˜-ëª¨ë¸-í•™ìŠµ">â†¥ back to top</a></b>
</div>
<br/>

### ë‘ ë¬¸ì¥ ê´€ê³„ ë¶„ë¥˜ í•™ìŠµ
- 80:20ìœ¼ë¡œ í•™ìŠµ ì²˜ë¦¬!
- train: 15170, dev: 3752
- Dataset ì¤€ë¹„ ë¶€ë¶„ ì•„ì´ë””ì–´ê°€ ë„ˆë¬´ ì¢‹ì•˜ìŒ
- ë¶„ë¥˜ëŠ” ê·¸ëƒ¥ Single Sentenceì™€ ë‹¤ë¥¼ ë°” ì—†ìŒ

<br/>
<div align="right">
    <b><a href="#6ê°•-bert-ê¸°ë°˜-ë‘-ë¬¸ì¥-ê´€ê³„-ë¶„ë¥˜-ëª¨ë¸-í•™ìŠµ">â†¥ back to top</a></b>
</div>
<br/>

### BERT IRQA ê¸°ë°˜ì˜ ì±—ë´‡ ì‹¤ìŠµ
- ìœ„ì—ì„œ í•™ìŠµí•œ ëª¨ë¸ë¡œ ì±—ë´‡ ì‹¤ìŠµ

```python
$ git clone https://github.com/songys/Chatbot_data.git
data.head()
```
|   |                         Q |                   A | label |
|--:|--------------------------:|--------------------:|------:|
| 0 |                  12ì‹œ ë•¡! |   í•˜ë£¨ê°€ ë˜ ê°€ë„¤ìš”. |     0 |
| 1 |       1ì§€ë§ í•™êµ ë–¨ì–´ì¡Œì–´ |    ìœ„ë¡œí•´ ë“œë¦½ë‹ˆë‹¤. |     0 |
| 2 |      3ë°•4ì¼ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤ | ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ . |     0 |
| 3 | 3ë°•4ì¼ ì •ë„ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤ | ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ . |     0 |
| 4 |                PPL ì‹¬í•˜ë„¤ |  ëˆˆì‚´ì´ ì°Œí‘¸ë ¤ì§€ì£ . |     0 |

- Top nê°œì˜ ë¬¸ì¥ì„ ë½‘ì„ ê²ƒì„

```python
chatbot_Question = data['Q'].values
chatbot_Answer = data['A'].values
print(chatbot_Question)
print(chatbot_Answer)
print(len(chatbot_Question), len(chatbot_Answer))
```
```
['12ì‹œ ë•¡!' '1ì§€ë§ í•™êµ ë–¨ì–´ì¡Œì–´' '3ë°•4ì¼ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤' ... 'í‘ê¸°ì‚¬ í•´ì£¼ëŠ” ì§ë‚¨.'
 'í˜ë“  ì—°ì•  ì¢‹ì€ ì—°ì• ë¼ëŠ”ê²Œ ë¬´ìŠ¨ ì°¨ì´ì¼ê¹Œ?' 'í˜ë“¤ì–´ì„œ ê²°í˜¼í• ê¹Œë´']
['í•˜ë£¨ê°€ ë˜ ê°€ë„¤ìš”.' 'ìœ„ë¡œí•´ ë“œë¦½ë‹ˆë‹¤.' 'ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .' ... 'ì„¤ë œê² ì–´ìš”.'
 'ì˜ í—¤ì–´ì§ˆ ìˆ˜ ìˆëŠ” ì‚¬ì´ ì—¬ë¶€ì¸ ê±° ê°™ì•„ìš”.' 'ë„í”¼ì„± ê²°í˜¼ì€ í•˜ì§€ ì•Šê¸¸ ë°”ë¼ìš”.']
11823 11823
```

- ìš°ì„  ì „ì²´ ì§ˆë¬¸ì— ëŒ€í•œ vector ì •ë³´ë¥¼ ì €ì¥
    - `bert-base-multilingual-cased` ë¡œ ìœ ì‚¬ë„ íšë“

```python
def get_cls_token(sent_A):
    model.eval()
    tokenized_sent = tokenizer(
            sent_A,
            return_tensors="pt",
            truncation=True,
            add_special_tokens=True,
            max_length=32
    ).to(device)
    with torch.no_grad():# ê·¸ë¼ë””ì—”íŠ¸ ê³„ì‚° ë¹„í™œì„±í™”
        outputs = model(
            input_ids=tokenized_sent['input_ids'],
            attention_mask=tokenized_sent['attention_mask'],
            token_type_ids=tokenized_sent['token_type_ids']
            )
    logits = outputs.last_hidden_state[:,0,:].detach().cpu().numpy()
    return logits


chatbot_Question_vectors = {}
for i, question in enumerate(chatbot_Question):
    chatbot_Question_vectors[i] = get_cls_token(question)
```

- ì „ì²´ ì§ˆë¬¸ê³¼ ìœ ì‚¬ë„ë¥¼ ê²€ì‚¬í•´ì„œ top-nê°œë¥¼ ë°˜í™˜í•˜ëŠ” ì½”ë“œ ì‘ì„±

```python
def custom_cosine_similarity(a,b):
    numerator = np.dot(a,b.T)
    a_norm = np.sqrt(np.sum(a * a))
    b_norm = np.sqrt(np.sum(b * b, axis=-1))

    denominator = a_norm * b_norm
    return numerator/denominator


def return_top_n_idx(question, n):
    question_vector = get_cls_token(question)
    sentence_similarity = {}
    for i in chatbot_Question_vectors.keys():
        ir_vector = chatbot_Question_vectors[i]
        similarity = custom_cosine_similarity(question_vector, ir_vector)
        sentence_similarity[i] = similarity

    sorted_sim = sorted(sentence_similarity.items(), key=lambda x: x[1], reverse=True)
    return sorted_sim[0:n]


# top 5ê°œ question idë¥¼ ë°˜í™˜
print(return_top_n_idx("ì˜¤ëŠ˜ ë„ˆë¬´ í˜ë“¤ì–´", 5))
```
```
[(3285, array([[0.97600377]], dtype=float32)), (7121, array([[0.9664848]], dtype=float32)), (5947, array([[0.9598295]], dtype=float32)), (5959, array([[0.95737875]], dtype=float32)), (7176, array([[0.9529198]], dtype=float32))]
```

- ìœ„ì˜ Question IDë¡œ `ì˜¤ëŠ˜ ë„ˆë¬´ í˜ë“¤ì–´`ì™€ ê°€ì¥ ê°€ê¹Œìš´ Qì™€ Aë¥¼ ì¶œë ¥

```python
print('most similar questions')
for result in return_top_n_idx("ì˜¤ëŠ˜ ë„ˆë¬´ í˜ë“¤ì–´", 5):
    print(chatbot_Question[result[0]])
print('\nmost similar answers')
for result in return_top_n_idx("ì˜¤ëŠ˜ ë„ˆë¬´ í˜ë“¤ì–´", 5):
    print(chatbot_Answer[result[0]])
```
```
most similar questions
ì˜¤ëŠ˜ ë„ˆë¬´ í˜ë“¤ë‹¤
ì˜¤ëŠ˜ ë„ˆë¬´ í˜ë“œë„¤
ë„ˆë¬´ í˜ë“¤ì–´
ë„ˆë¬´ë‚˜ë„ í˜ë“¤ì–´
ì˜¤ëŠ˜ë”°ë¼ ë„ˆë¬´ í˜ë“œë„¤

most similar answers
ê³ ìƒ ë§ì•˜ì–´ìš”.
ì˜¤ëŠ˜ì€ í˜ë‚´ë ¤ í•˜ì§€ ë§ì•„ìš”. ì €ì—ê²Œ ê¸°ëŒ€ì„¸ìš”.
ì§€ê¸ˆ ë¬´ìŠ¨ ë§ì„ í•´ë„ ì™€ë‹¿ì§€ ì•Šê² ì§€ë§Œ ì˜í•  ìˆ˜ ìˆì„ ê±°ì˜ˆìš”.
ì–µì§€ë¡œë¼ë„ ê¸ì •ì ì¸ ìƒê°ì„ í•´ë³´ì„¸ìš”.
í˜ë“  ë‚ ì´ë„¤ìš”.
```

- Top 1ì˜ ê²°ê³¼ê°€ ì •ë‹µì´ ì•„ë‹Œ ê²½ìš°ê°€ ìˆìŒ
    - ë„ˆ ëˆ„êµ¬ì•¼? í˜ë“¤ ë•Œ ê°™ì´ ìˆëŠ” ê±°ìš” ã…
    - ë§ì´ ì•ˆë˜ì£ ?

```
Q: ë„ˆ ì´ë¦„ì´ ë­ì•¼?

==== Most Similar Questions ====
ìš°ì •ì´ ë­ì•¼?
ë„ˆ ë­ë‹ˆ?
í•  ì¤„ ì•„ëŠ”ê±° ë­ì•¼?
ì‚¬ë‘ì˜ ëì´ ë­ì•¼?
ë„ˆ ëˆ„êµ¬?

==== Most Similar Answers ====
í˜ë“¤ ë•Œ ê°™ì´ ìˆëŠ” ê±°ìš”.
ì €ëŠ” ìœ„ë¡œë´‡ì…ë‹ˆë‹¤.
ë‹¹ì‹ ì˜ ì‚¶ì„ ì‘ì›í•´ ë“œë¦´ ìˆ˜ ìˆì–´ìš”ë¼ê³  ê°íˆ ë§í•´ ë´…ë‹ˆë‹¤.
ì‚¬ë‘í•˜ì§€ ì•ŠëŠ” ê²ƒì´ì£ .
ì €ëŠ” ë§ˆìŒì„ ì´ì–´ì£¼ëŠ” ìœ„ë¡œë´‡ì…ë‹ˆë‹¤.
```

- ì•ì„  ì˜ˆì œì—ì„œ í•™ìŠµí•œ BERT ë¶„ë¥˜ ëª¨ë¸ì„ load í›„ ìœ„ì—ì„œ ìœ ì‚¬í•˜ë‹¤ê³  íŒë‹¨ëœ ê²°ê³¼ë¥¼ ë¶„ë¥˜
    - 0: "non_similar", 1: "similar"

```
print(sentences_predict('ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì–´ë•Œìš”?','ì˜¤ëŠ˜ì˜ ë‚ ì”¨ë¥¼ ì•Œë ¤ì¤˜')) # similar
print(sentences_predict('ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì–´ë•Œìš”?','ê¸°ë¶„ ì§„ì§œ ì•ˆì¢‹ë‹¤.')) # non_similar
print(sentences_predict('ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì–´ë•Œìš”?','ì˜¤ëŠ˜ ê¸°ë¶„ ì–´ë– ì„¸ìš”?')) # non_similar
print(sentences_predict('ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì–´ë•Œìš”?','ì˜¤ëŠ˜ ê¸°ë¶„ì´ ì–´ë•Œìš”?')) # non_similar
print(sentences_predict('ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì–´ë•Œìš”?','ì§€ê¸ˆ ë‚ ì”¨ê°€ ì–´ë•Œìš”?')) # non_similar
print(sentences_predict('ë¬´í˜‘ ì†Œì„¤ ì¶”ì²œí•´ì£¼ì„¸ìš”.','ë¬´í˜‘ ì¥ë¥´ì˜ ì†Œì„¤ ì¶”ì²œ ë¶€íƒë“œë¦½ë‹ˆë‹¤.')) # similar
print(sentences_predict('ë¬´í˜‘ ì†Œì„¤ ì¶”ì²œí•´ì£¼ì„¸ìš”.','íŒíƒ€ì§€ ì†Œì„¤ ì¶”ì²œí•´ì£¼ì„¸ìš”.')) # non_similar
print(sentences_predict('ë¬´í˜‘ ì†Œì„¤ ì¶”ì²œí•´ì£¼ì„¸ìš”.','ë¬´í˜‘ ëŠë‚Œë‚˜ëŠ” ì†Œì„¤ í•˜ë‚˜ ì¶”ì²œí•´ì£¼ì‹¤ ìˆ˜ ìˆìœ¼ì‹¤ê¹Œìš”?')) # similar
print(sentences_predict('ë©”ë‚œë¯¼ì´ ë­ì•¼','ë„ˆ ë©”ë‚œë¯¼ì´ì§€?')) # similar
```

- ì±—ë´‡ êµ¬í˜„!

```python
def get_answer(question, n):
    results = return_top_n_idx(question, n) # top nê°œë¥¼ listë¡œ ë°›ê³ 
    for result in results:  # nê°œë¥¼ ë°˜ë³µë¬¸ì„ ëŒë©´ì„œ
        ir_answer = chatbot_Answer[result[0]]
        ir_question = chatbot_Question[result[0]]
        if sentences_predict(question, ir_question) == 1:   # ì´ì§„ë¶„ë¥˜ ëª¨ë¸ì´ query<->questionì˜ ì˜ë¯¸ê°€ ì„œë¡œ ê°™ë‹¤ê³  íŒë‹¨ë˜ë©´?
            return ir_answer    # ì •ë‹µì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    return chatbot_Answer[results[0][0]]    # "ì˜ ëª¨ë¥´ê² ì–´ìš”."
```

<br/>
<div align="right">
    <b><a href="#6ê°•-bert-ê¸°ë°˜-ë‘-ë¬¸ì¥-ê´€ê³„-ë¶„ë¥˜-ëª¨ë¸-í•™ìŠµ">â†¥ back to top</a></b>
</div>
<br/>
